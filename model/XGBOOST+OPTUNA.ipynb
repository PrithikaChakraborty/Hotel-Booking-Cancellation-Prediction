{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA97i5CW2jLE"
      },
      "outputs": [],
      "source": [
        "!pip install -q optuna xgboost lightgbm catboost category_encoders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfUMzxHL2qYw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, roc_auc_score, classification_report,\n",
        "    confusion_matrix, precision_recall_fscore_support\n",
        ")\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "import category_encoders as ce\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "def summarize_results(y_true, y_prob, threshold=0.5, label=\"Model\"):\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1  = f1_score(y_true, y_pred)\n",
        "    auc = roc_auc_score(y_true, y_prob)\n",
        "    print(f\"[{label}]  Acc: {acc:.4f} | F1: {f1:.4f} | ROC-AUC: {auc:.4f} | thr={threshold:.3f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred, digits=4))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "    return {\"accuracy\": acc, \"f1\": f1, \"roc_auc\": auc, \"threshold\": threshold}\n",
        "\n",
        "def best_threshold_by_metric(y_true, y_prob, metric=\"accuracy\"):\n",
        "    # Search thresholds on a fine grid and pick the best for the chosen metric\n",
        "    thresholds = np.linspace(0.05, 0.95, 181)\n",
        "    best_thr, best_score = 0.5, -1\n",
        "    for t in thresholds:\n",
        "        y_pred = (y_prob >= t).astype(int)\n",
        "        if metric == \"f1\":\n",
        "            score = f1_score(y_true, y_pred)\n",
        "        elif metric == \"accuracy\":\n",
        "            score = accuracy_score(y_true, y_pred)\n",
        "        else:\n",
        "            raise ValueError(\"metric must be 'accuracy' or 'f1'\")\n",
        "        if score > best_score:\n",
        "            best_score, best_thr = score, t\n",
        "    return best_thr, best_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CT6armmx2r8q"
      },
      "outputs": [],
      "source": [
        "# Set your path; if running locally in Colab after uploading, this usually works:\n",
        "csv_path = \"/content/hotel_bookings.csv\"\n",
        "assert Path(csv_path).exists(), f\"CSV not found at {csv_path}\"\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "print(df.shape)\n",
        "print(df.head(3))\n",
        "print(df.isnull().sum().sort_values(ascending=False).head(10))\n",
        "print(df['is_canceled'].value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtSPsbr92t-I"
      },
      "outputs": [],
      "source": [
        "df_clean = df.copy()\n",
        "\n",
        "# Drop known leakage / non-predictive columns\n",
        "# reservation_status_date leaks the future; reservation_status is a direct outcome label.\n",
        "for col in [\"reservation_status_date\", \"reservation_status\"]:\n",
        "    if col in df_clean.columns:\n",
        "        df_clean.drop(columns=[col], inplace=True)\n",
        "\n",
        "# Map month names to numbers (if present)\n",
        "if \"arrival_date_month\" in df_clean.columns and df_clean[\"arrival_date_month\"].dtype == object:\n",
        "    month_map = {'January':1,'February':2,'March':3,'April':4,'May':5,'June':6,\n",
        "                 'July':7,'August':8,'September':9,'October':10,'November':11,'December':12}\n",
        "    df_clean[\"arrival_date_month\"] = df_clean[\"arrival_date_month\"].map(month_map)\n",
        "\n",
        "# Feature engineering\n",
        "if set([\"stays_in_weekend_nights\",\"stays_in_week_nights\"]).issubset(df_clean.columns):\n",
        "    df_clean[\"total_nights\"] = df_clean[\"stays_in_weekend_nights\"] + df_clean[\"stays_in_week_nights\"]\n",
        "\n",
        "if set([\"adults\",\"children\",\"babies\"]).issubset(df_clean.columns):\n",
        "    df_clean[\"children\"] = df_clean[\"children\"].fillna(0)  # occasional NaNs\n",
        "    df_clean[\"total_guests\"] = df_clean[\"adults\"] + df_clean[\"children\"] + df_clean[\"babies\"]\n",
        "    df_clean[\"has_children\"] = (df_clean[\"children\"] > 0).astype(int)\n",
        "    df_clean[\"has_babies\"]   = (df_clean[\"babies\"] > 0).astype(int)\n",
        "    df_clean[\"is_family\"]    = ((df_clean[\"children\"] > 0) | (df_clean[\"babies\"] > 0)).astype(int)\n",
        "\n",
        "# Target & features\n",
        "y = df_clean[\"is_canceled\"].astype(int)\n",
        "X = df_clean.drop(columns=[\"is_canceled\"])\n",
        "\n",
        "# Identify columns\n",
        "num_cols = X.select_dtypes(include=[\"number\",\"float\",\"int\"]).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "print(\"Numerical:\", len(num_cols), num_cols[:10], \"...\")\n",
        "print(\"Categorical:\", len(cat_cols), cat_cols[:10], \"...\")\n",
        "\n",
        "# Train/Test split (stratified)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmjWA_Y32xAe"
      },
      "outputs": [],
      "source": [
        "# Decide which categorical columns are high-cardinality\n",
        "high_card_cols = [c for c in cat_cols if X_train[c].nunique() > 30]\n",
        "low_card_cols  = [c for c in cat_cols if c not in high_card_cols]\n",
        "\n",
        "print(\"High-cardinality:\", high_card_cols)\n",
        "print(\"Low-cardinality:\", low_card_cols)\n",
        "\n",
        "# Preprocessors:\n",
        "#  - Numerical: median impute (trees don't need scaling)\n",
        "#  - Low-card cats: OneHotEncoder handle_unknown='ignore'\n",
        "#  - High-card cats: TargetEncoder (supervised) -> use only on train folds internally via pipeline\n",
        "numeric_transformer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "low_card_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
        "])\n",
        "\n",
        "high_card_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"target\", ce.TargetEncoder(handle_missing=\"value\", handle_unknown=\"value\", smoothing=0.3, min_samples_leaf=20))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, num_cols),\n",
        "        (\"lowcard\", low_card_transformer, low_card_cols),\n",
        "        (\"highcard\", high_card_transformer, high_card_cols),\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUiHWmAC3BdY"
      },
      "outputs": [],
      "source": [
        "# Class imbalance ratio for XGBoost\n",
        "pos = y_train.sum()\n",
        "neg = (y_train == 0).sum()\n",
        "scale_pos_weight = max(1.0, neg / max(1, pos))\n",
        "\n",
        "def xgb_objective(trial):\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 1200),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 12),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-4, 3.0, log=True),\n",
        "        \"random_state\": RANDOM_STATE,\n",
        "        \"objective\": \"binary:logistic\",\n",
        "        \"eval_metric\": \"auc\",\n",
        "        \"tree_method\": \"hist\",\n",
        "        \"scale_pos_weight\": scale_pos_weight\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBClassifier(**params)\n",
        "\n",
        "    # Build full pipeline each fold to avoid leakage\n",
        "    pipe = Pipeline(steps=[(\"prep\", preprocessor), (\"model\", model)])\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "    aucs = []\n",
        "\n",
        "    for train_idx, valid_idx in cv.split(X_train, y_train):\n",
        "        X_tr, X_va = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
        "        y_tr, y_va = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
        "\n",
        "        pipe.fit(X_tr, y_tr)  # No early stopping here\n",
        "        y_va_prob = pipe.predict_proba(X_va)[:, 1]\n",
        "        aucs.append(roc_auc_score(y_va, y_va_prob))\n",
        "\n",
        "    return np.mean(aucs)\n",
        "\n",
        "# Run Optuna study\n",
        "xgb_study = optuna.create_study(direction=\"maximize\")\n",
        "xgb_study.optimize(xgb_objective, n_trials=40, show_progress_bar=True)\n",
        "\n",
        "print(\"Best XGB params:\", xgb_study.best_params)\n",
        "print(\"Best CV AUC:\", xgb_study.best_value)\n",
        "\n",
        "# Train final model with best params\n",
        "best_xgb = xgb.XGBClassifier(\n",
        "    **xgb_study.best_params,\n",
        "    random_state=RANDOM_STATE,\n",
        "    objective=\"binary:logistic\",\n",
        "    eval_metric=\"auc\",\n",
        "    tree_method=\"hist\",\n",
        "    scale_pos_weight=scale_pos_weight\n",
        ")\n",
        "\n",
        "xgb_pipe = Pipeline(steps=[(\"prep\", preprocessor), (\"model\", best_xgb)])\n",
        "xgb_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_test_prob_xgb = xgb_pipe.predict_proba(X_test)[:, 1]\n",
        "thr_acc_xgb, acc_xgb = best_threshold_by_metric(y_test, y_test_prob_xgb, metric=\"accuracy\")\n",
        "thr_f1_xgb, f1_xgb = best_threshold_by_metric(y_test, y_test_prob_xgb, metric=\"f1\")\n",
        "\n",
        "print(f\"\\n[XGB] Best threshold by accuracy: {thr_acc_xgb:.3f} (acc={acc_xgb:.4f})\")\n",
        "res_xgb_acc = summarize_results(y_test, y_test_prob_xgb, threshold=thr_acc_xgb, label=\"XGB-OPT (accuracy-opt)\")\n",
        "\n",
        "print(f\"\\n[XGB] Best threshold by F1: {thr_f1_xgb:.3f} (f1={f1_xgb:.4f})\")\n",
        "res_xgb_f1 = summarize_results(y_test, y_test_prob_xgb, threshold=thr_f1_xgb, label=\"XGB-OPT (f1-opt)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL0f8WLN3DdF"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save trained pipeline (preprocessor + XGB model)\n",
        "joblib.dump(xgb_pipe, \"xgb_pipe_model.pkl\")\n",
        "joblib.dump(xgb_study, \"xgb_optuna_study.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBvCgB-93PGo"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "# --- SHAP explainability for tuned XGBoost ---\n",
        "# Extract the fitted model from pipeline\n",
        "best_xgb_model = xgb_pipe.named_steps[\"model\"]\n",
        "\n",
        "# Get processed feature names from preprocessor\n",
        "feature_names = xgb_pipe.named_steps[\"prep\"].get_feature_names_out()\n",
        "\n",
        "# Use TreeExplainer for XGBoost\n",
        "explainer = shap.TreeExplainer(best_xgb_model)\n",
        "\n",
        "# Important: transform X_train with preprocessor (since pipeline hides this step)\n",
        "X_train_processed = xgb_pipe.named_steps[\"prep\"].transform(X_train)\n",
        "\n",
        "# Compute SHAP values (may be heavy â†’ sample if large dataset)\n",
        "shap_values = explainer.shap_values(X_train_processed)\n",
        "\n",
        "# --- Plots ---\n",
        "# Summary plot (global importance)\n",
        "shap.summary_plot(shap_values, X_train_processed, feature_names=feature_names)\n",
        "\n",
        "# Bar plot version\n",
        "shap.summary_plot(shap_values, X_train_processed, feature_names=feature_names, plot_type=\"bar\")\n",
        "\n",
        "# Dependence plot (example: top feature)\n",
        "top_feature = feature_names[np.argsort(np.abs(shap_values).mean(0))[::-1][0]]\n",
        "shap.dependence_plot(top_feature, shap_values, X_train_processed, feature_names=feature_names)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
